{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMQhhVF/KOjcvbgvbqqIyKv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wW-1NVjtgmIY","executionInfo":{"status":"ok","timestamp":1751734519515,"user_tz":-300,"elapsed":69929,"user":{"displayName":"saleem muhammad","userId":"02293328178523817561"}},"outputId":"60f4e097-e081-467a-bade-5944dedc5bbd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":18,"metadata":{"id":"zKA2Zr0JgMso","executionInfo":{"status":"ok","timestamp":1751734982038,"user_tz":-300,"elapsed":174,"user":{"displayName":"saleem muhammad","userId":"02293328178523817561"}}},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","source":["!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml\n","!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_eye.xml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VdE1qYDiiQN","executionInfo":{"status":"ok","timestamp":1751734958133,"user_tz":-300,"elapsed":795,"user":{"displayName":"saleem muhammad","userId":"02293328178523817561"}},"outputId":"9cd348a0-dfe9-42df-b485-5b113ba30485"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-07-05 17:04:28--  https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml [following]\n","--2025-07-05 17:04:28--  https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 930127 (908K) [text/plain]\n","Saving to: â€˜haarcascade_frontalface_default.xmlâ€™\n","\n","\r          haarcasca   0%[                    ]       0  --.-KB/s               \rhaarcascade_frontal 100%[===================>] 908.33K  --.-KB/s    in 0.008s  \n","\n","2025-07-05 17:04:28 (112 MB/s) - â€˜haarcascade_frontalface_default.xmlâ€™ saved [930127/930127]\n","\n","--2025-07-05 17:04:28--  https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_eye.xml\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml [following]\n","--2025-07-05 17:04:28--  https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 341406 (333K) [text/plain]\n","Saving to: â€˜haarcascade_eye.xmlâ€™\n","\n","haarcascade_eye.xml 100%[===================>] 333.40K  --.-KB/s    in 0.006s  \n","\n","2025-07-05 17:04:28 (52.1 MB/s) - â€˜haarcascade_eye.xmlâ€™ saved [341406/341406]\n","\n"]}]},{"cell_type":"code","source":["face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"],"metadata":{"id":"WnXQC8MmgVfh","executionInfo":{"status":"ok","timestamp":1751734961792,"user_tz":-300,"elapsed":175,"user":{"displayName":"saleem muhammad","userId":"02293328178523817561"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["eye_cascade=cv2.CascadeClassifier('haarcascade_eye.xml')"],"metadata":{"id":"gfwC1NlbgZ8u","executionInfo":{"status":"ok","timestamp":1751734963492,"user_tz":-300,"elapsed":179,"user":{"displayName":"saleem muhammad","userId":"02293328178523817561"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["video_path = '/content/drive/My Drive/MemoryLane 416/Birthday of Zohaib.mp4'"],"metadata":{"id":"xlNCFzgPg-kV","executionInfo":{"status":"ok","timestamp":1751734964699,"user_tz":-300,"elapsed":180,"user":{"displayName":"saleem muhammad","userId":"02293328178523817561"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["cap=cv2.VideoCapture(video_path)\n","if not cap.isOpened():\n","  print(\"Error opening video file\")\n","  exit()"],"metadata":{"id":"S295Q6Nhgdog","executionInfo":{"status":"ok","timestamp":1751734965923,"user_tz":-300,"elapsed":153,"user":{"displayName":"saleem muhammad","userId":"02293328178523817561"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    flip = cv2.flip(frame, 0)\n","    gray = cv2.cvtColor(flip, cv2.COLOR_BGR2GRAY)\n","    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(flip, (x,y), (x+w, y+h), (255,0,0), 2)\n","        gray_roi = gray[y:y+h, x:x+w]\n","        color_roi = flip[y:y+h, x:x+w]\n","        eyes = eye_cascade.detectMultiScale(gray_roi)\n","        for (ex, ey, ew, eh) in eyes:\n","            cv2.rectangle(color_roi, (ex,ey), (ex+ew, ey+eh), (0,255,0), 2)\n","    cv2_imshow(flip)\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1wha-6FtBm7yO4UNSajPUGSZs6v0_3y2y"},"collapsed":true,"id":"G-70fhm1hGKc","executionInfo":{"status":"error","timestamp":1751735076466,"user_tz":-300,"elapsed":80842,"user":{"displayName":"saleem muhammad","userId":"02293328178523817561"}},"outputId":"c7ddf6b9-c60b-4128-ba69-072c33e1c1f4"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["\n","### ðŸ”· **Code Explanation**\n","\n","```python\n","while True:\n","```\n","\n","âœ… **Starts an infinite loop** to process video frames continuously.\n","\n","---\n","\n","```python\n","    ret, frame = cap.read()\n","```\n","\n","âœ… **Reads a frame** from your video capture (`cap`).\n","\n","* `ret` is `True` if a frame was read successfully.\n","* `frame` is the actual image/frame.\n","\n","---\n","\n","```python\n","    if not ret:\n","        break\n","```\n","\n","âœ… **If no frame is read**, break the loop.\n","(This prevents errors when video ends or webcam disconnects.)\n","\n","---\n","\n","```python\n","    flip = cv2.flip(frame, 0)\n","```\n","\n","âœ… **Flips the frame vertically**.\n","\n","* `0` means vertical flip (upside down).\n","* Useful if your webcam or video feed is inverted.\n","\n","---\n","\n","```python\n","    gray = cv2.cvtColor(flip, cv2.COLOR_BGR2GRAY)\n","```\n","\n","âœ… Converts the flipped frame to **grayscale**.\n","Why?\n","\n","* Face and eye detection using Haar cascades **works on grayscale images** for faster processing.\n","\n","---\n","\n","```python\n","    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))\n","```\n","\n","âœ… Uses the **face cascade classifier** to detect faces in the grayscale frame.\n","\n","**Parameters:**\n","\n","* `scaleFactor=1.1`\n","  How much the image size is reduced at each image scale. Smaller values = slower but better detection.\n","\n","* `minNeighbors=5`\n","  How many neighbors each candidate rectangle should have to retain it. Higher = fewer detections, more confidence.\n","\n","* `minSize=(30,30)`\n","  Minimum size of detected faces.\n","\n","---\n","\n","```python\n","    for (x, y, w, h) in faces:\n","```\n","\n","âœ… **Loops through each detected face**.\n","Each face is represented by **(x,y,w,h)**:\n","\n","* `(x,y)` â†’ top-left corner of face rectangle\n","* `(w,h)` â†’ width and height\n","\n","---\n","\n","```python\n","        cv2.rectangle(flip, (x,y), (x+w, y+h), (255,0,0), 2)\n","```\n","\n","âœ… **Draws a blue rectangle** around the detected face on the flipped frame.\n","\n","* `(255,0,0)` is **blue color** in BGR.\n","* `2` is thickness.\n","\n","---\n","\n","```python\n","        gray_roi = gray[y:y+h, x:x+w]\n","        color_roi = flip[y:y+h, x:x+w]\n","```\n","\n","âœ… Defines **Region of Interest (ROI)** within the face for detecting eyes:\n","\n","* `gray_roi`: grayscale face region.\n","* `color_roi`: color face region (for drawing rectangles).\n","\n","---\n","\n","```python\n","        eyes = eye_cascade.detectMultiScale(gray_roi)\n","```\n","\n","âœ… Uses the **eye cascade classifier** to detect eyes **within the grayscale face region**.\n","\n","---\n","\n","```python\n","        for (ex, ey, ew, eh) in eyes:\n","```\n","\n","âœ… **Loops through each detected eye**.\n","Each eye is represented by `(ex, ey, ew, eh)` **relative to the face region**.\n","\n","---\n","\n","```python\n","            cv2.rectangle(color_roi, (ex,ey), (ex+ew, ey+eh), (0,255,0), 2)\n","```\n","\n","âœ… **Draws a green rectangle** around each detected eye on `color_roi`.\n","\n","* `(0,255,0)` is green.\n","\n","---\n","\n","```python\n","    cv2_imshow(flip)\n","```\n","\n","\n"],"metadata":{"id":"Ps-Q4fvLjHun"}}]}